# Frage
Welche Metriken zur Evaluation der binären Klassifikation kennen Sie? Erklären Sie 2 davon mit jeweils 2 Sätzen.

# Antwort
### Genauigkeit (Accuracy)
Die Genauigkeit misst das Verhältnis der korrekt vorhergesagten Instanzen (beide Klassen) zur Gesamtanzahl der Instanzen im Testdatensatz. Sie gibt an, wie viele Vorhersagen insgesamt korrekt sind. Diese Metrik kann in unbalancierten Klassenverhältnissen irreführend sein.

### Präzision (Precision):
Die Präzision misst den Anteil der tatsächlichen positiven Instanzen (Klasse 1), die korrekt vorhergesagt wurden, an allen vorhergesagten positiven Instanzen. Sie betont die Qualität der positiven Vorhersagen und ist besonders nützlich, wenn falsch positive Vorhersagen problematisch sind.

#### Recall (Sensitivität oder True Positive Rate):
Der Recall misst den Anteil der tatsächlichen positiven Instanzen, die korrekt vorhergesagt wurden, an allen tatsächlichen positiven Instanzen. Er betont die Fähigkeit des Modells, alle tatsächlichen positiven Instanzen zu erfassen, und ist besonders wichtig, wenn falsch negative Vorhersagen problematisch sind.

#### F1-Score:
Der F1-Score ist das harmonische Mittel zwischen Präzision und Recall. Er kombiniert Informationen über die Qualität der positiven Vorhersagen (Präzision) und die Fähigkeit, positive Instanzen zu erfassen (Recall), und ist nützlich, wenn ein Gleichgewicht zwischen Präzision und Recall angestrebt wird.

#### AUC-ROC (Area Under the Receiver Operating Characteristic Curve):
Die ROC-Kurve zeigt das Verhältnis zwischen True Positive Rate (Recall) und False Positive Rate bei verschiedenen Schwellenwerten für die Klassifikation. Die AUC-ROC misst die gesamte Leistung des Modells unabhängig vom gewählten Schwellenwert und ist besonders nützlich, wenn die Klassifikationsschwelle variieren kann.

#### AUC-PR (Area Under the Precision-Recall Curve):
Die PR-Kurve zeigt das Verhältnis zwischen Präzision und Recall bei verschiedenen Schwellenwerten. Die AUC-PR misst die Fläche unter der PR-Kurve und eignet sich besonders gut für unbalancierte Datensätze.

Diese Metriken bieten unterschiedliche Einblicke in die Leistung eines Klassifikationsmodells und werden je nach den Anforderungen des Anwendungsfalls ausgewählt.